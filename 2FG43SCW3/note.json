{
  "paragraphs": [
    {
      "text": "%spark.pyspark\n\n# define the data frame source on the given column selection/predicates:\ndf \u003d sqlContext.read.parquet(\n    \"/hadoop/gaia/parquet/gdr2/gaia_source/*.parquet\"\n    ).select(\n    [\"designation\",\"source_id\",\"ra\",\"ra_error\",\"dec\",\"dec_error\",\"parallax\",\"parallax_error\",\"parallax_over_error\",\"pmra\",\"pmra_error\",\"pmdec\",\"pmdec_error\",\"l\",\"b\"]\n    ).where(\n    \"abs(b) \u003c 30.0 AND parallax \u003e 1.0 and parallax_over_error \u003e 10.0 AND phot_g_mean_flux_over_error \u003e 36.19 AND astrometric_sigma5d_max \u003c 0.3 AND visibility_periods_used \u003e 8 AND (astrometric_excess_noise \u003c 1 OR (astrometric_excess_noise \u003e 1 AND astrometric_excess_noise_sig \u003c 2))\"\n    )\n\n# sanity check\ndf.show()\nprint (\"Data frame rows: \",df.count())",
      "user": "admin",
      "dateUpdated": "2020-09-24 17:27:01.018",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+--------------------+-------------------+------------------+--------------------+-------------------+--------------------+------------------+--------------------+-------------------+--------------------+--------------------+-------------------+--------------------+------------------+-------------------+\n|         designation|          source_id|                ra|            ra_error|                dec|           dec_error|          parallax|      parallax_error|parallax_over_error|                pmra|          pmra_error|              pmdec|         pmdec_error|                 l|                  b|\n+--------------------+-------------------+------------------+--------------------+-------------------+--------------------+------------------+--------------------+-------------------+--------------------+--------------------+-------------------+--------------------+------------------+-------------------+\n|Gaia DR2 40396662...|4039666296672658688|272.42180060744215|0.040014912399424604|  -33.6058067001021| 0.03368056050988915| 1.422454370334301| 0.03639988616495275|           39.07854| -0.2316953688797376| 0.07537877095615261| -5.442599071096166| 0.05727019630225524|358.50569414878646|-6.7818037118031835|\n|Gaia DR2 40396673...|4039667327461865216|272.65050482164776|0.036197874417770184| -33.67244054531187| 0.03680133647540661|1.1673137239965692| 0.05314058363370944|           21.96652| -1.7009801509860536| 0.07029452441830816| -4.612361250689048| 0.06085092511704771|358.53690441856696| -6.981138715828702|\n|Gaia DR2 40396638...|4039663822768546432| 272.3987836204827|0.027632276638390182|-33.677978944324124|0.024215370325550427| 1.485547221111856|0.028698903012696158|          51.763206|  -4.537954548081503|0.053742838174843835|-15.585752841174445|0.041699306844425514| 358.4325162212831| -6.799004597798456|\n|Gaia DR2 40396743...|4039674302495016832| 272.6370332645537|0.049971393914832546| -33.46345401655811| 0.04311907194434805|1.4895944391179747| 0.05535383094438027|          26.910412|  -8.999004938426811| 0.08901429663519801|-20.520372339141726| 0.07278953875661565| 358.7173313727555| -6.872875125255238|\n|Gaia DR2 40396798...|4039679804475284224| 272.3352958925287|  0.0382698356897684| -33.49684273645387|   0.037562716485539|1.8288406168863958|0.049118014784077936|            37.2336|  -8.709127050643408| 0.07206191453025368| 0.8317008127357967| 0.05431303815619029|  358.568061282215|  -6.66676412739173|\n|Gaia DR2 40396768...|4039676845112356736| 272.3423038848421| 0.04004613278050688| -33.60277422977108| 0.03534959354180454| 1.331757953116398|0.040852709757309896|           32.59901| -3.0736631636887344| 0.07887016066616566|-10.535097449648152| 0.06167703651701124|358.47687324908384| -6.722021120385618|\n|Gaia DR2 40396799...|4039679976215199616| 272.3870770186676| 0.08175560039135911| -33.49054936039203|   0.075806277430834|1.6828015366409843| 0.09616438158987135|          17.499218|  0.9078068372385885|    0.15609879018991|-1.2743414940340876| 0.12356941230805032| 358.5942080511929|  -6.70183491892182|\n|Gaia DR2 40396779...|4039677948992976896| 272.2946282491588| 0.12673632257759757|-33.562874682533035| 0.11352057025821762|1.2791078599019605| 0.12717607561652478|          10.057771|  2.4788330269377497|  0.2613657929145823| -4.650451848991806| 0.20943502287503454| 358.4933431825897| -6.668151666197993|\n|Gaia DR2 40396646...|4039664686186893184| 272.4026652887885|0.028595834471134035|-33.655006326453886| 0.02471972176840793|1.4230023257454893|0.029119862707883994|           48.86707|  -4.179903049739455|0.055444952571015844| 2.2287270254996123|  0.0428403985184529| 358.4544442439153| -6.791000148338951|\n|Gaia DR2 40396753...|4039675333287149952|  272.560428244972| 0.14485939823543023| -33.41907979107032| 0.13639184748166955|2.4892891798856938| 0.14768574894726139|           16.85531|   2.753665468378671|  0.2764468222685262| -6.187195733058044|  0.2210087660210865|358.72641382590615| -6.795584005240619|\n|Gaia DR2 40396696...|4039669629564951040| 272.7381011527819|0.054428306834246126| -33.56432279582611| 0.04383693249181095|1.4039064198829385| 0.06633427846464744|          21.164116|   3.411131784353724| 0.09135111973361876| -9.646276318124418| 0.08216672365634985| 358.6675940515556| -6.994684164951169|\n|Gaia DR2 40396626...|4039662693254567936| 272.5126080410794|  0.1296423098745303| -33.65215003086476| 0.10917065938921705|1.2421645377888288|  0.1122515594329213|            11.0659|    7.70196276687754| 0.25578905728633683|-17.583724821676032| 0.20088518616997741| 358.5004815041314| -6.870335004176007|\n|Gaia DR2 40396725...|4039672520147052672|272.57023824221136|  0.0736686882516885| -33.51129861096017| 0.06447426562797175| 1.186762299958647| 0.08862786004612552|          13.390398|   2.632117122829801| 0.13686967280780654| 0.3072041918179895|  0.1083246074218071|358.64839146395377| -6.846275843225122|\n|Gaia DR2 40396727...|4039672721944070272| 272.5831112426574| 0.07043976875751465|-33.483537099952784| 0.06291530701296215|  1.14022685446635| 0.08033686117429235|          14.193072|  0.5481922043982299|   0.129302666462865|-3.2025426136016226| 0.10287713081563385|358.67814785261555|-6.8426601585483455|\n|Gaia DR2 40396731...|4039673134263578112|272.47253543660037|0.041702049821903266| -33.51891353312088| 0.03645176703075055|1.1267320071311797|0.047071092260350056|          23.936815|  -1.641507160720163| 0.07769872412607842| -4.671616157042623| 0.06032524035452944| 358.6029327525877| -6.778040244101522|\n|Gaia DR2 40396646...|4039664686186892160|272.40377537872985| 0.04377600533015369| -33.65486867142623|0.037860082819238965|  1.75887165621122|  0.0445294022348985|          39.499107| -0.9566730190113414| 0.08496727540942774| -3.746117897740997|   0.066416625862686|358.45500600935554|  -6.79174955438742|\n|Gaia DR2 40396815...|4039681591181083520| 272.1513758092714| 0.03374330430351806| -33.54770223115408| 0.03215174942793003|1.2770089043898252| 0.03768576974690001|          33.885704| -14.528880635531543| 0.06242652192511705|-1.5617009216815694| 0.05084214045259791|  358.449834180826| -6.555840447573484|\n|Gaia DR2 40396683...|4039668396976095232| 272.5918785069274| 0.06755164731288285| -33.62795490984999|0.060064042374027175| 1.278165908009941| 0.08163770487003097|          15.656564|  -9.059932437739432| 0.12441941818286029| 1.0153309974276419| 0.10066735403770635|358.55330353126215| -6.917141240695328|\n|Gaia DR2 40396782...|4039678253864546816| 272.2796609111014| 0.12881518153071386| -33.51657315885373| 0.11029532166270983|1.1790261056103815| 0.11170275683028853|          10.555032|  -9.837527608593797|  0.2374980846729896| -4.101407578324116|  0.1907102657065912|358.52845560549713| -6.635240808816544|\n|Gaia DR2 40396815...|4039681591181086848| 272.1520450526198| 0.04506019510179999| -33.54255938796362| 0.04309540098315705|1.0121130032598475| 0.04860285626079909|          20.824146|-0.01420160186318746| 0.08474653494512939|-4.1072215733651944| 0.07023090482212226|358.45465735183967| -6.553891056963974|\n+--------------------+-------------------+------------------+--------------------+-------------------+--------------------+------------------+--------------------+-------------------+--------------------+--------------------+-------------------+--------------------+------------------+-------------------+\nonly showing top 20 rows\n\nData frame rows:  21901470\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1598271181307_869304795",
      "id": "20200527-131424_279716502",
      "dateCreated": "2020-08-24 12:13:01.307",
      "dateStarted": "2020-09-24 17:27:01.088",
      "dateFinished": "2020-09-24 17:38:00.182",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\n\nfrom numpy import pi, cos, sin\nimport numpy as np\n\ndf.columns",
      "user": "gaiauser",
      "dateUpdated": "2020-09-24 15:19:43.953",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "[\u0027designation\u0027,\n \u0027source_id\u0027,\n \u0027ra\u0027,\n \u0027ra_error\u0027,\n \u0027dec\u0027,\n \u0027dec_error\u0027,\n \u0027parallax\u0027,\n \u0027parallax_error\u0027,\n \u0027parallax_over_error\u0027,\n \u0027pmra\u0027,\n \u0027pmra_error\u0027,\n \u0027pmdec\u0027,\n \u0027pmdec_error\u0027,\n \u0027l\u0027,\n \u0027b\u0027]"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1598271181308_1629634898",
      "id": "20200527-131448_1345258690",
      "dateCreated": "2020-08-24 12:13:01.309",
      "dateStarted": "2020-09-24 15:19:43.985",
      "dateFinished": "2020-09-24 15:19:44.024",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\n\n# Generic functions used later\n\ndef convDegRad(args, units\u003d\"degrees\"):\n    \u0027\u0027\u0027\n    NAME\n        convDegRad\n        \n    FUNCTION\n        args in km/sTransforms degrees to radians or returns radians if in radians\n        \n    INPUT\n         args - list of values to convert\n        units - [\u0027degrees\u0027, \u0027radians\u0027] Units of args\n    \n    OUTPUT\n    list of args in radians\n    \u0027\u0027\u0027\n\n    if units \u003d\u003d \u0027degrees\u0027:\n        args \u003d [i*pi/180 for i in args]\n\n    return args\n\ndef convMasKm(args, parallax, units\u003d \u0027mas/yr\u0027):\n    \u0027\u0027\u0027\n    NAME\n        convMasKm\n        \n    FUNCTION\n        Converts data from mas/yr to km/s\n        \n    INPUT\n            args - list of values to convert\n        parallax - parallax of argsmeasurements\n           units - [\u0027mas/yr\u0027, \u0027km/s\u0027] Units of args\n    \n    OUTPUT\n        list of args in km/s\n    \u0027\u0027\u0027\n    \n    if units \u003d\u003d \u0027mas/yr\u0027:\n        k \u003d 4.74057\n        args \u003d [i/parallax * 4.74057 for i in args]\n    elif units !\u003d \u0027km/s\u0027:\n        raise ValueError(\"Input proper motion values in either mas/yr or km/s\")\n        \n    return args\n\ndef matrix_multiplication_arrays(A,B):\n    \u0027\u0027\u0027NAME\n         matrix_multiplication_arrays\n        \n    FUNCTION\n        Matrix multiplication of Matrix A and B if both are either lists or numpy.arrays\n        \n    INPUT\n        A - Matrix A\n        B - Matrix B\n    \n    OUTPUT\n        MAtrix A*B, as an numpy.array\n    \u0027\u0027\u0027\n    \n    if np.shape(A)[1] !\u003d np.shape(B)[0]:\n        return \u0027Invalid matrix shape\u0027\n    else:\n        n,m \u003d np.shape(A)[0], np.shape(B)[1]\n        M \u003d np.zeros((n,m))\n        \n        for i in range(n):\n            for j in range(len(B[0])):\n                E\u003d0\n                for k in range(len(B)):\n#                     print(\u0027A{}{}*B{}{}\u0027.format(i,k,k,j))\n                    E +\u003d A[i][k]*B[k][j]\n                M[i,j] \u003d E\n#                 print(\u0027\\n\u0027)\n        return M\n        \n",
      "user": "gaiauser",
      "dateUpdated": "2020-09-24 15:16:00.124",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1598271181309_1244388368",
      "id": "20200527-131600_314491974",
      "dateCreated": "2020-08-24 12:13:01.309",
      "dateStarted": "2020-09-24 15:16:00.186",
      "dateFinished": "2020-09-24 15:18:02.092",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\n\n# Functions to perform the LSR cut\n\ndef create_Matrix_A(ra, dec, coord_units \u003d \u0027degrees\u0027):\n    \u0027\u0027\u0027creates Matrix A, where A \u003d [[cos(ra)*cos(dec), -sin(ra), -cos(ra)*sin(dec)],\n                                     [sin(ra)*cos(dec),  cos(ra), -sin(ra)*sin(dec)],\n                                     [sin(dec),             0,     cos(dec)]])\u0027\u0027\u0027\n    \n#     if all(v is None for v in {data, ra, dec}):\n#         raise ValueError(\"Expected input either as array or \u0027ra\u0027 and \u0027dec\u0027 values\")\n#     if data is None:\n#         if any(v is None for v in {ra,dec}):\n#             raise ValueError(\"Expected input either as array or \u0027ra\u0027 and \u0027dec\u0027 values\")\n\n    ra,dec \u003d convDegRad([ra,dec], units \u003d coord_units)  # Ensures radians\n        \n    A \u003d np.array([[cos(ra)*cos(dec), -sin(ra), -cos(ra)*sin(dec)],\n              [sin(ra)*cos(dec), cos(ra), -sin(ra)*sin(dec)],\n              [sin(dec), 0, cos(dec)]])\n    return A\n\ndef create_matrix_C(pmra, pmdec, parallax \u003d None, radial_velocity \u003d 0.0, units \u003d \u0027mas/yr\u0027):\n    \u0027\u0027\u0027creates Matrix C, where C \u003d [radial_velocity, pmra, pmdec]\u0027\u0027\u0027\n    \n    if parallax \u003d\u003d None and units \u003d\u003d \u0027mas/yr\u0027:\n        raise ValueError(\"Parallax value must be supplied if proper motion units are \u0027mas/yr\u0027\")\n\n    pmra,pmdec \u003d convMasKm([pmra, pmdec], parallax \u003d parallax, units \u003d units)  # Ensures proper motions in km/s\n    C \u003d np.array([[radial_velocity, pmra, pmdec]]).T\n    \n    \n    return C\n    \ndef conv_Galactic_LSR(G, magnitude \u003d True):\n    \u0027\u0027\u0027\n    NAME\n        conv_Galactic_LSR\n        \n    FUNCTION\n        Calculates magnitude of LSR velocity give U,V,W velocity.\n        \n    INPUT\n                G - Array of U, W, V velocity in Galactic reference frame\n        Magnitude - [True, False] Return velocity magnitude (True) or LSR components (False)\n    \n    OUTPUT\n        LSR velocity values\n    \n    SEE ALSO\n        v_sun values from Schonrich, R., Binney, J., \u0026 Dehnen, W. 2010 | \n        DOI: 10.1111/j.1365-2966.2010.16253.x\n    \u0027\u0027\u0027\n    v_sun \u003d [11.1, 12.24, 7.25]\n    lsr \u003d np.asarray(G).T + v_sun\n    \n    if magnitude \u003d\u003d True:\n        v_lsr \u003d np.sqrt(np.sum([i**2 for i in lsr]))\n        return v_lsr\n    return lsr\n    \ndef LSR_conv(ra, dec, parallax, pmra, pmdec, coord_units \u003d \u0027degrees\u0027, pm_units\u003d\u0027mas/yr\u0027, radial_velocity \u003d 0.0, magnitude \u003d True):\n    \u0027\u0027\u0027\n    NAME\n        LSR_conv\n        \n    FUNCTION\n        Converts proper motions from ra, dec to LSR velocity\n    \n    REQUIRES:\n              ra - right acension of object\n             dec - declination of object\n        parallax - parallax of object\n            pmra - right ascension component of proper motion\n           pmdec - declination component of proper motion\n        \n    OPTIONAL:\n            coord_units \u003d [defaut \u003d \u0027deg\u0027] units of coordinates (ra, dec). \n                                Accepted values are [\u0027deg\u0027, \u0027rad\u0027]\n               pm_units \u003d [defaut \u003d \u0027mas/yr\u0027] units of proper motions. \n                              Accepted values are: [\u0027mas/yr\u0027, \u0027km/s\u0027]\n        radial_velocity \u003d list of radial velocity (defaults \u003d 0.0)\n                    mag \u003d Return only V_LSR mag (default \u003d True - returns three dimensions of v_lsr [u,v,w])\n    \n    RETURNS\n        lsr velocity [float]\n    \n    SEE ALSO\n         Method from: Johnson, Dean R. H., Soderblom, David R. DOI: 10.1086/114370\n    \u0027\u0027\u0027\n    \n    T \u003d [[-0.05646624, -0.87325802, -0.48397519],\n         [ 0.49253617, -0.44602111,  0.74731071],\n         [-0.86845823, -0.19617746,  0.4552963 ]]\n\n    A \u003d create_Matrix_A(ra,dec, coord_units\u003dcoord_units)   # forms Marix A\n    B \u003d matrix_multiplication_arrays(T, A)  # forms Matrix B\n    \n    C \u003d create_matrix_C(pmra,pmdec,parallax, units \u003d pm_units, radial_velocity \u003d radial_velocity)    # forms Matrix C\n    G \u003d matrix_multiplication_arrays(B,C) # Calculates U, W, V\n\n    v_lsr \u003d conv_Galactic_LSR(G, magnitude \u003d magnitude) # Calculates velocity magnitude in LSR coords\n    \n    return v_lsr",
      "user": "gaiauser",
      "dateUpdated": "2020-09-24 15:19:20.872",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1598271181310_491685421",
      "id": "20200527-131651_2073984980",
      "dateCreated": "2020-08-24 12:13:01.310",
      "dateStarted": "2020-09-24 15:19:20.908",
      "dateFinished": "2020-09-24 15:19:20.961",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\n\n# This function needs to be called by the UDF, all optional parameters are set as required - e.g. show_velocity \u003d False.\n\ndef LSR_cut(ra,dec,parallax,pmra,pmdec, \n            cut \u003d 60, coord_units \u003d \u0027degrees\u0027, \n            pm_units\u003d\u0027mas/yr\u0027, show_velocity \u003d False):\n    \u0027\u0027\u0027\n    NAME\n        LSR_cut\n        \n    FUNCTION\n        Calculates LSR velocity through LSR_conv and returns boolean if satisfies cut condition.\n    \n    REQUIRES:\n              ra - right acension of object\n             dec - declination of object\n        parallax - parallax of object\n            pmra - right ascension component of proper motion\n           pmdec - declination component of proper motion\n    \n    OPTIONAL\n          coord_units \u003d [defaut \u003d \u0027deg\u0027] units of coordinates (ra, dec). \n                             Accepted values are [\u0027deg\u0027, \u0027rad\u0027]\n             pm_units \u003d [defaut \u003d \u0027mas/yr\u0027] units of proper motions. \n                            Accepted values are: [\u0027mas/yr\u0027, \u0027km/s\u0027]\n        show_velocity \u003d [default \u003d False] print lsr velocity? [True/False]\n    \n    RETURNS\n        [Boolean]\n    \u0027\u0027\u0027\n    \n    v \u003d LSR_conv(ra,dec,parallax,pmra,pmdec, coord_units\u003dcoord_units, pm_units\u003dpm_units)\n    if show_velocity \u003d\u003d True:\n        print(v)\n    if v \u003c cut:\n        return 1\n    if v \u003e cut:\n        return 0\n        \n        \n# EXAMPLE\n        \nra,dec,parallax,pmra,pmdec \u003d 57.25900743047902,14.667417479835972,1.9984319162609905,-2.1574156360679533, -9.231775664473664\nLSR_cut(ra, dec, parallax, pmra, pmdec, cut \u003d 60, show_velocity \u003d True)",
      "user": "gaiauser",
      "dateUpdated": "2020-09-24 15:19:49.478",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "21.34521829551358\n1"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1598271181311_941050788",
      "id": "20200527-131951_1295526984",
      "dateCreated": "2020-08-24 12:13:01.311",
      "dateStarted": "2020-09-24 15:19:49.514",
      "dateFinished": "2020-09-24 15:19:49.556",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\nfrom pyspark.sql.types import IntegerType\nspark.udf.register(\"udf_lsr_cut\", LSR_cut, IntegerType())\ndf_lsr_cut \u003d df.select(\"*\").where(\"udf_lsr_cut(ra, dec, parallax, pmra, pmdec) \u003d 1\")\n",
      "user": "gaiauser",
      "dateUpdated": "2020-09-24 15:19:52.625",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1598271181311_-1035005376",
      "id": "20200527-132100_1979599614",
      "dateCreated": "2020-08-24 12:13:01.311",
      "dateStarted": "2020-09-24 15:19:52.655",
      "dateFinished": "2020-09-24 15:19:52.781",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\ndf_lsr_cut.columns\n",
      "user": "gaiauser",
      "dateUpdated": "2020-09-24 15:19:55.204",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "[\u0027designation\u0027,\n \u0027source_id\u0027,\n \u0027ra\u0027,\n \u0027ra_error\u0027,\n \u0027dec\u0027,\n \u0027dec_error\u0027,\n \u0027parallax\u0027,\n \u0027parallax_error\u0027,\n \u0027parallax_over_error\u0027,\n \u0027pmra\u0027,\n \u0027pmra_error\u0027,\n \u0027pmdec\u0027,\n \u0027pmdec_error\u0027,\n \u0027l\u0027,\n \u0027b\u0027]"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1598271181312_-933829439",
      "id": "20200605-164933_241111883",
      "dateCreated": "2020-08-24 12:13:01.312",
      "dateStarted": "2020-09-24 15:19:55.228",
      "dateFinished": "2020-09-24 15:19:55.278",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\n# Convert to Pandas (will be interesting to see if there are any differences with Pandas and Koalas for performance)\n\ncols\u003d[\u0027l\u0027, \u0027b\u0027, \u0027parallax\u0027,\u0027pmra\u0027,\u0027pmdec\u0027]\n\ndef convert_dataframe(df, cols, package \u003d \u0027pandas\u0027):\n    \u0027\u0027\u0027converts pyspark dataframe to pandas or koalas\u0027\u0027\u0027\n    \n    if package \u003d\u003d \u0027pandas\u0027:\n        # Pandas version\n        import pandas as pd\n        pdf \u003d df_lsr_cut.select(cols).toPandas()\n        return pdf\n        \n    if package \u003d\u003d \u0027koalas\u0027:\n         # Koalas version\n        import koalas as ks\n        kdf \u003d df_lsr_cut.select(cols).to_koalas()\n        return kdf\n\ndf_HDBSCAN \u003d convert_dataframe(df_lsr_cut, cols, package \u003d \u0027pandas\u0027)",
      "user": "gaiauser",
      "dateUpdated": "2020-09-24 15:19:56.968",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1598271181312_16446805",
      "id": "20200709-153147_80241281",
      "dateCreated": "2020-08-24 12:13:01.312",
      "dateStarted": "2020-09-24 15:19:56.990",
      "dateFinished": "2020-09-24 15:39:39.284",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\ndfnew \u003d df_HDBSCAN.head(5000000)\n",
      "user": "gaiauser",
      "dateUpdated": "2020-09-24 15:45:37.380",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1598961875059_159155373",
      "id": "20200901-120435_886409485",
      "dateCreated": "2020-09-01 12:04:35.059",
      "dateStarted": "2020-09-24 15:45:37.417",
      "dateFinished": "2020-09-24 15:45:37.459",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n\nz.put(\"dfnew\", dfnew)",
      "user": "gaiauser",
      "dateUpdated": "2020-09-24 15:45:41.784",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)\n\u001b[0;32m\u003cipython-input-24-61fd5a2c05f7\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dfnew\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m: \u0027IPySparkZeppelinContext\u0027 object has no attribute \u0027put\u0027"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1598965972742_-1960789826",
      "id": "20200901-131252_1293540008",
      "dateCreated": "2020-09-01 13:12:52.743",
      "dateStarted": "2020-09-24 15:45:41.817",
      "dateFinished": "2020-09-24 15:45:41.897",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n\nimport hdbscan\n\ndef clustering_info(clusterer, add_to_data\u003dFalse, df\u003d[], index\u003d-1):\n    \u0027\u0027\u0027\n    REQUIRED\n        clusterer \u003d output clusterer from HDBSCAN.\n        \n    OPTIONAL\n        add_to_data \u003d [boolean] Add results to df or return as arrays.\n        df \u003d [Required if add_to_data \u003d True] DataFrame to add results.\n        index \u003d [Default \u003d -1] Column location to add results.\n        \n    RETURNS\n        *groups \u003d Cluster labels for each point in the dataset given to fit(). \n                   Noisy samples are given the label -1.\n        *prob \u003d The strength with which each sample is a member of its assigned cluster.\n        *persistence \u003d A score of how persistent each cluster is. \n                       A score of 1.0 represents a perfectly stable cluster. \n    \n        if add_to_data \u003d False, returns [groups, prob, persistence] as seperate arrays.\n        if add_to_data \u003d True - returns df(DataFrame), persistence (array) - Must provide df to add.\n        \n        (*From HDBSCAN - in SEE ALSO)\n        \n    SEE ALSO\n        https://hdbscan.readthedocs.io/en/latest/\n    \u0027\u0027\u0027\n    # probabilities and group for each object\n    prob\u003dclusterer.probabilities_\n    groups\u003dclusterer.labels_\n\n    # Info on persistence of groups\n    persistence\u003dclusterer.cluster_persistence_\n    \n    print(\u0027Number of Groups \u003d \u0027, max(groups)+1) \n    if add_to_data \u003d\u003d False:\n        return groups, prob, persistence\n    \n    if add_to_data \u003d\u003d True:\n        df\u003dinsert_to_df(df, \u0027group\u0027, groups, index\u003dindex)\n        df\u003dinsert_to_df(df,\u0027probability\u0027, prob, index\u003dindex)\n        return df, persistence\n    \ndef clustering_prediction(clusterer, points_to_predict, cols, add_to_data\u003dFalse, index\u003d-1):\n    \u0027\u0027\u0027\n    REQUIRED\n        clusterer \u003d output clusterer from HDBSCAN.\n        points_to_predict \u003d DataFrame of objects to predict relationships to clustered data.\n        cols \u003d list of columns used for clustering.\n    \n    OPTIONAL\n        add_to_data \u003d [boolean] Add results to points_to_predict or return as arrays.\n        index \u003d [Default \u003d -1] Column location to add results.\n        \n    RETURNS\n        *group \u003d The predicted labels of the points_to_predict\n        *prob \u003d The soft cluster scores for each of the points_to_predict\n        \n        if add_to_data\u003dFalse, returns [group, prob] as seperate arrays.\n        if add_to_data\u003dTrue - returns df(DataFrame) with group and prob added.\n        \n        (*From HDBSCAN - in SEE ALSO)\n        \n    SEE ALSO\n        https://hdbscan.readthedocs.io/en/latest/\n    \u0027\u0027\u0027\n    \n    groups, prob \u003d hdbscan.approximate_predict(clusterer, points_to_predict[cols])\n    if add_to_data \u003d\u003d False:\n        return groups, prob\n    \n    if add_to_data \u003d\u003d True:\n        points_to_predict\u003dinsert_to_df(points_to_predict, \u0027group\u0027, groups, index\u003dindex)\n        points_to_predict\u003dinsert_to_df(points_to_predict,\u0027probability\u0027, prob, index\u003dindex)\n        return points_to_predict\n        \n     \n        \n# Apply HDBSCAN for full data with prediction ON.\n\nclusterer \u003d hdbscan.HDBSCAN(min_cluster_size\u003d40, \n                            min_samples\u003d25,\n                            prediction_data\u003dTrue, \n                            allow_single_cluster\u003dFalse,\n#                             memory\u003d\u0027data/leaf_cache/\u0027,\n                            cluster_selection_method\u003d\u0027leaf\u0027,\n                            gen_min_span_tree\u003dTrue).fit(df)\n\n",
      "user": "gaiauser",
      "dateUpdated": "2020-09-24 15:45:55.532",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n\u001b[0;32m\u003cipython-input-26-ab8cf6dd7f8b\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m#                             memory\u003d\u0027data/leaf_cache/\u0027,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                             \u001b[0mcluster_selection_method\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;34m\u0027leaf\u0027\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 87\u001b[0;31m                             gen_min_span_tree\u003dTrue).fit(df)\n\u001b[0m\n\u001b[0;32m~/.local/lib/python3.7/site-packages/hdbscan/hdbscan_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \"\"\"\n\u001b[1;32m    897\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m!\u003d\u001b[0m \u001b[0;34m\u0027precomputed\u0027\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 898\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;34m\u0027csr\u0027\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_data\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    547\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 549\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m\u003d\u003d\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray\u003dDataFrame[designation: string, source_id: bigint, ra: double, ra_error: double, dec: double, dec_error: double, parallax: double, parallax_error: double, parallax_over_error: float, pmra: double, pmra_error: double, pmdec: double, pmdec_error: double, l: double, b: double].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1598271181313_290822531",
      "id": "20200605-165000_1292852380",
      "dateCreated": "2020-08-24 12:13:01.313",
      "dateStarted": "2020-09-24 15:45:55.559",
      "dateFinished": "2020-09-24 15:45:55.921",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\n# collect results from HDBSCAN\ndata, persistence \u003d clustering_info(clusterer, True, dfnew)\nprint(data.columns)\n#data.to_csv(\"data/DR2_with_groups_leaf.csv\", index\u003dNone)\n\n# Collect prediction data from HDBSCAN\n\n# wdcols\u003d[\u0027l\u0027,\u0027b\u0027,\u0027Plx\u0027, \u0027pmRA\u0027, \u0027pmDE\u0027]    # Naming WD columns\n# print(WDs.columns)\n# WDs\u003dclustering_prediction(clusterer, WDs, wdcols,  True) \n# WDs.to_csv(\"data/WDs_with_groups_leaf.csv\", index\u003dNone)\n# print(\u0027WDs check complete\u0027)",
      "user": "admin",
      "dateUpdated": "2020-09-01 12:31:40.720",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "Number of Groups \u003d  77\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n\u001b[0;32m\u003cipython-input-48-8916d4b97a7f\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# collect results from HDBSCAN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersistence\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mclustering_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusterer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#data.to_csv(\"data/DR2_with_groups_leaf.csv\", index\u003dNone)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;32m\u003cipython-input-44-2decfb988e85\u003e\u001b[0m in \u001b[0;36mclustering_info\u001b[0;34m(clusterer, add_to_data, df, index)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0madd_to_data\u001b[0m \u001b[0;34m\u003d\u003d\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 40\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0minsert_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\u0027group\u0027\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0minsert_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u0027probability\u0027\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersistence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;31mNameError\u001b[0m: name \u0027insert_to_df\u0027 is not defined"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1598271181313_608152456",
      "id": "20200709-153048_444614899",
      "dateCreated": "2020-08-24 12:13:01.313",
      "dateStarted": "2020-09-01 12:31:40.737",
      "dateFinished": "2020-09-01 12:31:40.819",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\ndf.printSchema()\n",
      "user": "admin",
      "dateUpdated": "2020-09-24 17:34:58.550",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "root\n |-- designation: string (nullable \u003d true)\n |-- source_id: long (nullable \u003d true)\n |-- ra: double (nullable \u003d true)\n |-- ra_error: double (nullable \u003d true)\n |-- dec: double (nullable \u003d true)\n |-- dec_error: double (nullable \u003d true)\n |-- parallax: double (nullable \u003d true)\n |-- parallax_error: double (nullable \u003d true)\n |-- parallax_over_error: float (nullable \u003d true)\n |-- pmra: double (nullable \u003d true)\n |-- pmra_error: double (nullable \u003d true)\n |-- pmdec: double (nullable \u003d true)\n |-- pmdec_error: double (nullable \u003d true)\n |-- l: double (nullable \u003d true)\n |-- b: double (nullable \u003d true)\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1598271181314_-1700135226",
      "id": "20200821-082350_10618326",
      "dateCreated": "2020-08-24 12:13:01.314",
      "dateStarted": "2020-09-24 17:34:58.612",
      "dateFinished": "2020-09-24 17:38:00.186",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\nimport pandas as pd\npd.DataFrame(df.take(5), columns\u003ddf.columns).transpose()",
      "user": "admin",
      "dateUpdated": "2020-09-24 17:38:11.259",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "                                                0  ...                             4\ndesignation          Gaia DR2 4039666296672658688  ...  Gaia DR2 4039679804475284224\nsource_id                     4039666296672658688  ...           4039679804475284224\nra                                        272.422  ...                       272.335\nra_error                                0.0400149  ...                     0.0382698\ndec                                      -33.6058  ...                      -33.4968\ndec_error                               0.0336806  ...                     0.0375627\nparallax                                  1.42245  ...                       1.82884\nparallax_error                          0.0363999  ...                      0.049118\nparallax_over_error                       39.0785  ...                       37.2336\npmra                                    -0.231695  ...                      -8.70913\npmra_error                              0.0753788  ...                     0.0720619\npmdec                                     -5.4426  ...                      0.831701\npmdec_error                             0.0572702  ...                      0.054313\nl                                         358.506  ...                       358.568\nb                                         -6.7818  ...                      -6.66676\n\n[15 rows x 5 columns]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1600968898550_-1969256415",
      "id": "20200924-173458_703494874",
      "dateCreated": "2020-09-24 17:34:58.550",
      "dateStarted": "2020-09-24 17:38:11.302",
      "dateFinished": "2020-09-24 17:38:12.717",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\nfrom pyspark.ml.classification import RandomForestClassifier\nrf \u003d RandomForestClassifier(featuresCol \u003d \u0027features\u0027, labelCol \u003d \u0027label\u0027)\nrfModel \u003d rf.fit(df)\npredictions \u003d rfModel.transform(test)\npredictions.select(\u0027age\u0027, \u0027job\u0027, \u0027label\u0027, \u0027rawPrediction\u0027, \u0027prediction\u0027, \u0027probability\u0027).show(10)\n",
      "user": "admin",
      "dateUpdated": "2020-09-24 17:38:53.113",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {}
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "Fail to execute line 3: rfModel \u003d rf.fit(train)\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-256223068579870178.py\", line 375, in \u003cmodule\u003e\n    exec(code, _zcUserQueryNameSpace)\n  File \"\u003cstdin\u003e\", line 3, in \u003cmodule\u003e\nNameError: name \u0027train\u0027 is not defined\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1600969091259_-1364258807",
      "id": "20200924-173811_401830272",
      "dateCreated": "2020-09-24 17:38:11.259",
      "dateStarted": "2020-09-24 17:38:43.474",
      "dateFinished": "2020-09-24 17:38:43.716",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\n\nimport pyspark.ml\ndf.printSchema()\n",
      "user": "admin",
      "dateUpdated": "2020-09-24 17:47:41.839",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "root\n |-- designation: string (nullable \u003d true)\n |-- source_id: long (nullable \u003d true)\n |-- ra: double (nullable \u003d true)\n |-- ra_error: double (nullable \u003d true)\n |-- dec: double (nullable \u003d true)\n |-- dec_error: double (nullable \u003d true)\n |-- parallax: double (nullable \u003d true)\n |-- parallax_error: double (nullable \u003d true)\n |-- parallax_over_error: float (nullable \u003d true)\n |-- pmra: double (nullable \u003d true)\n |-- pmra_error: double (nullable \u003d true)\n |-- pmdec: double (nullable \u003d true)\n |-- pmdec_error: double (nullable \u003d true)\n |-- l: double (nullable \u003d true)\n |-- b: double (nullable \u003d true)\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1600969123437_-909195917",
      "id": "20200924-173843_899891566",
      "dateCreated": "2020-09-24 17:38:43.437",
      "dateStarted": "2020-09-24 17:47:41.862",
      "dateFinished": "2020-09-24 17:47:41.874",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\n",
      "user": "admin",
      "dateUpdated": "2020-09-24 17:39:37.088",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1600969177088_1315208217",
      "id": "20200924-173937_507924516",
      "dateCreated": "2020-09-24 17:39:37.088",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "~Trash/experiments/stv/kounkelcoveyUDF",
  "id": "2FG43SCW3",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}